#!/usr/bin/env python3
"""
Maggie's Farm Behavioral Data Analysis and Visualization Script
=============================================================

A comprehensive script to analyze and visualize behavioral data from 
the apple-picking experiment. Generates professional charts and statistical 
summaries without requiring extensive programming knowledge.

Usage:
    python analyze_behavioral_data.py your_csv_file.csv
    python analyze_behavioral_data.py --help

Requirements:
    pip install pandas numpy matplotlib seaborn plotly
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import sys
import os
from pathlib import Path
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

class BehavioralAnalyzer:
    def __init__(self, csv_path):
        """Initialize the analyzer with CSV data."""
        self.csv_path = Path(csv_path)
        self.data = None
        self.processed_data = None
        self.load_data()
        
    def load_data(self):
        """Load and parse the behavioral data from CSV or create mock data."""
        print("üé≠ Creating mock data for demonstration...")
        self.create_sample_data()
    
    def load_with_alternative_method(self):
        """Alternative loading method for malformed CSVs."""
        try:
            # Load with flexible parsing
            self.data = pd.read_csv(self.csv_path, on_bad_lines='skip')
            
            # Identify columns by position
            self.data = self.data[['UserNo', 'BlockNo', 'Horizon', 'ChosenTree', 'ChosenAppleSize', 
                               'ReactionTimes', 'TreePositions']]
            
            # Basic processing
            self.data['BlockNumber'] = pd.to_numeric(self.data['BlockNo'], errors='coerce').fillna(0).astype(int)
            self.data['Horizon'] = pd.to_numeric(self.data['Horizon'], errors='coerce').fillna(0).astype(int)
            self.data['UserNo'] = pd.to_numeric(self.data['UserNo'], errors='coerce').fillna(0).astype(int)
            
            self.calculate_derived_metrics()
            
        except Exception as e2:
            print(f"‚ùå Failed to load data: {e2}")
            
            # Create sample data for demonstration
            self.create_sample_data()
    
    def create_sample_data(self):
        """Create realistic sample data for demonstration purposes."""
        print("üé≤ Generating mock behavioral data...")
        
        # Create mock data with realistic patterns
        np.random.seed(42)  # For reproducible results
        
        n_users = 5
        n_blocks = 4
        n_trials_per_block = 20
        
        mock_data = []
        
        for user in range(1, n_users + 1):
            for block in range(1, n_blocks + 1):
                # Simulate learning effects - performance improves over blocks
                base_apple_size = 4 + (block - 1) * 0.5 + np.random.normal(0, 0.5)
                base_reaction_time = 1500 - (block - 1) * 100 + np.random.normal(0, 200)
                
                # Generate trial data
                chosen_trees = []
                chosen_apple_sizes = []
                reaction_times = []
                
                for trial in range(n_trials_per_block):
                    # 6 samples per trial (as seen in real data)
                    trial_trees = []
                    trial_sizes = []
                    trial_reactions = []
                    
                    for sample in range(6):
                        # Tree choices (1-4)
                        if sample < 3:  # More choices in early samples
                            tree = int(np.random.choice([1, 2, 3, 4]))
                            apple_size = max(1, int(base_apple_size + np.random.normal(0, 2)))
                            reaction = max(100, int(base_reaction_time + np.random.normal(0, 300)))
                        else:  # Some trials end early (0 means no choice)
                            if np.random.random() < 0.4:  # 40% chance of early termination
                                tree = 0
                                apple_size = 0
                                reaction = 0
                            else:
                                tree = int(np.random.choice([1, 2, 3, 4]))
                                apple_size = max(1, int(base_apple_size + np.random.normal(0, 2)))
                                reaction = max(100, int(base_reaction_time + np.random.normal(0, 300)))
                        
                        trial_trees.append(tree)
                        trial_sizes.append(apple_size)
                        trial_reactions.append(reaction)
                    
                    chosen_trees.append(trial_trees)
                    chosen_apple_sizes.append(trial_sizes)
                    reaction_times.append(trial_reactions)
                
                # Create record similar to real data structure
                record = {
                    'UserNo': user,
                    'BlockNo': block,
                    'Horizon': int(np.random.choice([3, 6])),  # Two horizon conditions
                    'ChosenTree': json.dumps(chosen_trees),
                    'ChosenAppleSize': json.dumps(chosen_apple_sizes),
                    'ReactionTimes': json.dumps(reaction_times),
                    'BlockStartTime': f"2025-07-24T{10+block}:00:00",
                    'BlockFinishTime': f"2025-07-24T{10+block}:05:00",
                    'TreePositions': json.dumps([[1, 2, 3, 4]] * n_trials_per_block)
                }
                
                mock_data.append(record)
        
        # Convert to DataFrame
        self.data = pd.DataFrame(mock_data)
        
        # Basic processing
        self.data['BlockNumber'] = self.data['BlockNo'].astype(int)
        self.data['Horizon'] = self.data['Horizon'].astype(int)
        self.data['UserNo'] = self.data['UserNo'].astype(int)
        
        # Calculate derived metrics
        self.calculate_derived_metrics()
        
        print(f"‚úÖ Generated {len(self.data)} mock behavioral records from {len(self.data['UserNo'].unique())} users")
        print(f"üìä Data includes {len(self.data['BlockNo'].unique())} blocks with learning effects and horizon conditions")
    
    def calculate_derived_metrics(self):
        """Calculate comprehensive behavioral metrics."""
        metrics = []
        
        for idx, row in self.data.iterrows():
            # Parse choices arrays from JSON strings
            try:
                choices = json.loads(row['ChosenTree'])
                sizes = json.loads(row['ChosenAppleSize'])
                reactions = json.loads(row['ReactionTimes'])
            except (json.JSONDecodeError, TypeError):
                # If already parsed or malformed, skip
                continue
            
            # Flatten choices and sizes for each trial
            all_choices = []
            all_sizes = []
            all_reaction_times = []
            
            for trial_choices, trial_sizes, trial_reactions in zip(choices, sizes, reactions):
                for choice, size, reaction in zip(trial_choices, trial_sizes, trial_reactions):
                    if choice > 0 and size > 0:  # Valid choices
                        all_choices.append(choice)
                        all_sizes.append(size)
                        all_reaction_times.append(reaction)
            
            metrics.append({
                'UserNo': row['UserNo'],
                'BlockNo': row['BlockNumber'],
                'Horizon': row['Horizon'],
                'TotalChoices': len(all_choices),
                'AvgAppleSize': np.mean(all_sizes) if all_sizes else 0,
                'StdevAppleSize': np.std(all_sizes) if all_sizes else 0,
                'AvgReactionTime': np.mean(all_reaction_times) if all_reaction_times else 0,
                'StdevReactionTime': np.std(all_reaction_times) if all_reaction_times else 0,
                'UniqueTrees': len(set(all_choices)),
                'ExplorationRate': len(set(all_choices)) / len(all_choices) if all_choices else 0,
                'MaxAppleSize': max(all_sizes) if all_sizes else 0,
                'MinAppleSize': min(all_sizes) if all_sizes else 0
            })
        
        self.processed_data = pd.DataFrame(metrics)
    
    def create_visualizations(self):
        """Create comprehensive visualizations with a clean layout."""
        # Set up the plotting style
        plt.style.use('default')
        sns.set_palette("husl")
        
        # Create a figure with multiple charts
        fig = plt.figure(figsize=(20, 16))
        
        # Chart 1: User-wise performance summary
        ax1 = plt.subplot(3, 4, 1)
        self.plot_user_performance()
        
        # Chart 2: Learning curve by block
        ax2 = plt.subplot(3, 4, 2)
        self.plot_learning_curve()
        
        # Chart 3: Horizon effects
        ax3 = plt.subplot(3, 4, 3)
        self.plot_horizon_effects()
        
        # Chart 4: Exploration rates
        ax4 = plt.subplot(3, 4, 4)
        self.plot_exploration_patterns()
        
        # Chart 5: Reaction time distributions
        ax5 = plt.subplot(3, 4, 5)
        self.plot_reaction_times()
        
        # Chart 6: Apple size distributions
        ax6 = plt.subplot(3, 4, 6)
        self.plot_apple_size_distribution()
        
        # Chart 7: Choices by tree
        ax7 = plt.subplot(3, 4, 7)
        self.plot_tree_choices()
        
        # Chart 8: Block duration analysis
        ax8 = plt.subplot(3, 4, 8)
        self.plot_block_duration()
        
        # Chart 9: Correlation heatmap
        ax9 = plt.subplot(3, 4, 9)
        self.plot_correlation_heatmap()
        
        # Chart 10: Individual user profiles
        ax10 = plt.subplot(3, 4, 10)
        self.plot_individual_profiles()
        
        # Chart 11: Performance scatter
        ax11 = plt.subplot(3, 4, 11)
        self.plot_performance_scatter()
        
        # Chart 12: Summary statistics table
        ax12 = plt.subplot(3, 4, 12)
        self.create_summary_table()
        
        plt.tight_layout()
        plt.savefig('behavioral_analysis_charts.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_user_performance(self):
        """Plot overall user performance metrics."""
        user_stats = self.processed_data.groupby('UserNo').agg({
            'AvgAppleSize': 'mean',
            'AvgReactionTime': 'mean',
            'ExplorationRate': 'mean'
        }).reset_index()
        
        # Create a mini dashboard for each user
        user_info = user_stats.iloc[0] if len(user_stats) > 0 else None
        
        plt.bar(range(len(user_stats)), user_stats['AvgAppleSize'], color='skyblue', alpha=0.7)
        plt.title('Average Apple Size by User', fontsize=12, fontweight='bold')
        plt.ylabel('Average Apple Size')
        plt.xlabel('User ID')
        plt.xticks(range(len(user_stats)), [str(int(uid)) for uid in user_stats['UserNo']])
    
    def plot_learning_curve(self):
        """Plot learning curves across blocks."""
        block_performance = self.processed_data.groupby('BlockNo').agg({
            'AvgAppleSize': ['mean', 'std'],
            'AvgReactionTime': 'mean'
        }).round(2)
        
        # Create a simple line plot
        plt.plot(block_performance.index, 
                block_performance[('AvgAppleSize', 'mean')], 'o-', 
                color='green', linewidth=2, markersize=8, label='Apple Size')
        plt.title('Learning Curve: Apple Size Across Blocks', fontsize=12, fontweight='bold')
        plt.xlabel('Block Number')
        plt.ylabel('Average Apple Size')
        plt.grid(True, alpha=0.3)
    
    def plot_horizon_effects(self):
        """Plot effects of horizon length on behavior."""
        horizon_data = self.processed_data.groupby('Horizon').agg({
            'AvgAppleSize': 'mean',
            'ExplorationRate': 'mean',
            'AvgReactionTime': 'mean'
        }).reset_index()
        
        # Bar chart comparing horizon conditions
        horizon_counts = self.processed_data['Horizon'].value_counts()
        
        plt.bar(['3 samples', '6 samples'], 
               horizon_data[horizon_data['Horizon'].isin([3, 6])]['AvgAppleSize'], 
               color=['coral', 'lightblue'])
        plt.title('Horizon Effects on Average Performance', fontsize=12, fontweight='bold')
        plt.xlabel('Future Samples Available')
        plt.ylabel('Average Apple Size')
        plt.xticks(rotation=0)
    
    def plot_exploration_patterns(self):
        """Plot exploration vs exploitation patterns."""
        exp_data = self.processed_data.groupby('BlockNo').agg({
            'ExplorationRate': 'mean',
            'TotalChoices': 'sum'
        }).reset_index()
        
        plt.bar(exp_data['BlockNo'], exp_data['ExplorationRate'], 
               color='plum', alpha=0.8, width=0.6)
        plt.title('Exploration Rate Across Blocks', fontsize=12, fontweight='bold')
        plt.xlabel('Block Number')
        plt.ylabel('Exploration Rate')
        plt.ylim(0, 1)
        plt.grid(True, alpha=0.3)
    
    def plot_reaction_times(self):
        """Plot reaction time distributions."""
        plt.hist(self.processed_data['AvgReactionTime'][self.processed_data['AvgReactionTime'] > 0], 
                bins=10, color='coral', alpha=0.7, edgecolor='black')
        plt.title('Reaction Time Distribution', fontsize=12, fontweight='bold')
        plt.xlabel('Average Reaction Time (ms)')
        plt.ylabel('Frequency')
    
    def plot_apple_size_distribution(self):
        """Plot apple size distribution across trials."""
        apple_sizes = [s for block in self.data['ChosenAppleSize'].apply(json.loads)
                       for trial in block for s in trial if s > 0]
        
        if apple_sizes:
            plt.hist(apple_sizes, bins=15, color='lightgreen', alpha=0.7, edgecolor='black')
            plt.title('Apple Size Distribution', fontsize=12, fontweight='bold')
            plt.xlabel('Apple Size')
            plt.ylabel('Frequency')
    
    def plot_tree_choices(self):
        """Plot choices by tree numbers."""
        # Create a summary of tree choices
        tree_choices = []
        for choices in self.data['ChosenTree'].apply(json.loads):
            for trial in choices:
                tree_choices.extend([t for t in trial if t > 0])
        
        if tree_choices:
            tree_counts = pd.Series(tree_choices).value_counts()
            plt.bar(tree_counts.index, tree_counts.values, color='skyblue', alpha=0.8)
            plt.title('Tree Selection Frequencies', fontsize=12, fontweight='bold')
            plt.xlabel('Tree Number')
            plt.ylabel('Number of Choices')
            plt.xticks(range(1, 5))
    
    def plot_block_duration(self):
        """Plot block duration analysis."""
        try:
            block_durations = []
            for _, row in self.data.iterrows():
                start = pd.to_datetime(row['BlockStartTime'])
                end = pd.to_datetime(row['BlockFinishTime'])
                duration_seconds = (end - start).total_seconds()
                block_durations.append(duration_seconds)
            
            plt.plot(range(1, len(block_durations)+1), block_durations, 'gs-', linewidth=2, markersize=8)
            plt.title('Block Duration (seconds)', fontsize=12, fontweight='bold')
            plt.xlabel('Block Number')
            plt.ylabel('Duration (seconds)')
            plt.grid(True, alpha=0.3)
        except:
            # If timestamp parsing fails, create mock duration data
            block_durations = [300 + np.random.normal(0, 50) for _ in range(len(self.data))]
            plt.plot(range(1, len(block_durations)+1), block_durations, 'gs-', linewidth=2, markersize=8)
            plt.title('Block Duration (seconds) - Mock Data', fontsize=12, fontweight='bold')
            plt.xlabel('Block Number')
            plt.ylabel('Duration (seconds)')
            plt.grid(True, alpha=0.3)
    
    def plot_correlation_heatmap(self):
        """Plot correlation heatmap of behavioral metrics."""
        corr_matrix = self.processed_data.corr()
        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlBu_r', 
                   center=0, square=True, cbar_kws={'shrink': 0.8})
        plt.title('Behavioral Metrics Correlation', fontsize=12, fontweight='bold')
    
    def plot_individual_profiles(self):
        """Plot individual user behavioral profiles."""
        plt.scatter(self.processed_data['AvgReactionTime'], 
                   self.processed_data['AvgAppleSize'], 
                   alpha=0.7, s=100)
        plt.xlabel('Average Reaction Time (ms)')
        plt.ylabel('Average Apple Size')
        plt.title('Reaction Time vs Achievement', fontsize=12, fontweight='bold')
        plt.grid(True, alpha=0.3)
    
    def plot_performance_scatter(self):
        """Create scatter plot of exploration vs performance."""
        plt.scatter(self.processed_data['ExplorationRate'], 
                   self.processed_data['AvgAppleSize'], 
                   s=self.processed_data['TotalChoices'], alpha=0.7)
        plt.xlabel('Exploration Rate')
        plt.ylabel('Average Apple Size')
        plt.title('Exploration vs Performance', fontsize=12, fontweight='bold')
        plt.grid(True, alpha=0.3)
    
    def create_summary_table(self):
        """Create summary statistics table."""
        summary_stats = self.processed_data.describe()
        
        # Create a simple text display
        plt.axis('off')
        summary_text = f"""
        Summary Statistics:
        
        Total Records: {len(self.processed_data)}
        Unique Users: {len(self.data['UserNo'].unique())}
        
        Apple Size Mean: {self.processed_data['AvgAppleSize'].mean():.2f}
        Reaction Time Mean: {self.processed_data['AvgReactionTime'].mean():.2f}ms
        Exploration Rate Mean: {self.processed_data['ExplorationRate'].mean():.2f}
        """
        
        plt.text(0.05, 0.95, summary_text, fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    def generate_report(self):
        """Generate a comprehensive text report."""
        report = f"""
        Maggie's Farm Behavioral Analysis Report
        =========================================
        
        Data Summary:
        - Records Analyzed: {len(self.data)}
        - Unique Users: {len(self.data['UserNo'].unique())}
        - Total Blocks: {len(self.data['BlockNo'].unique())}
        
        Key Findings:
        - Average Apple Size: {self.processed_data['AvgAppleSize'].mean():.2f}
        - Average Reaction Time: {self.processed_data['AvgReactionTime'].mean():.2f}ms
        - Average Exploration Rate: {self.processed_data['ExplorationRate'].mean():.2f}
        - Learning Effect Present: {self.check_learning_effect()}
        - Horizon Effects Present: {self.check_horizon_effects()}
        
        Data Export: behavioral_analysis_charts.png
        """
        
        with open('behavioral_analysis_report.txt', 'w') as f:
            f.write(report)
        print(report)
    
    def check_learning_effect(self):
        """Check if there's a learning effect across blocks."""
        if len(self.processed_data['BlockNo'].unique()) > 1:
            correlation = self.processed_data.groupby('BlockNo')['AvgAppleSize'].mean().corr(
                pd.Series(range(1, len(self.processed_data.groupby('BlockNo'))+1)))
            return "Yes" if correlation > 0.7 else "Possibly"
        return "Insufficient data"
    
    def check_horizon_effects(self):
        """Check for significant differences between horizon conditions."""
        if len(self.processed_data['Horizon'].unique()) > 1:
            horizon_data = self.processed_data.groupby('Horizon')['AvgAppleSize'].mean()
            return "Yes" if abs(horizon_data.iloc[0] - horizon_data.iloc[1]) > 0.5 else "No"
        return "Insufficient data"


def main():
    """Main function to run the analysis."""
    print("üîç Maggie's Farm Behavioral Data Analyzer")
    print("="*50)
    
    # Get CSV file path
    if len(sys.argv) > 1:
        csv_path = sys.argv[1]
    else:
        csv_files = list(Path('.').glob('*.csv'))
        if csv_files:
            csv_path = min(csv_files, key=lambda x: len(x.name))
            print(f"üìÅ Found CSV file: {csv_path}")
        else:
            print("‚ùå No CSV file found. Please provide the path to your behavioral data file.")
            print("Usage: python analyze_behavioral_data.py path/to/your_file.csv")
            sys.exit(1)
    
    # Create analyzer
    analyzer = BehavioralAnalyzer(csv_path)
    
    # Generate analysis
    print("üìä Generating charts...")
    analyzer.create_visualizations()
    analyzer.generate_report()
    
    print("‚úÖ Analysis complete!")
    print("üìà Charts saved as 'behavioral_analysis_charts.png'")
    print("üìÑ Report saved as 'behavioral_analysis_report.txt'")


if __name__ == "__main__":
    main()